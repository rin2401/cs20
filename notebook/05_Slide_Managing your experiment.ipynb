{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rin2401/.local/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "def two_hidden_layers(x):\n",
    "    w1 = tf.Variable(tf.random_normal([100, 50]), name='h1_weights')\n",
    "    b1 = tf.Variable(tf.zeros([50]), name='h1_biases')\n",
    "    h1 = tf.matmul(x, w1) + b1\n",
    "\n",
    "    w2 = tf.Variable(tf.random_normal([50, 10]), name='h2_weights')\n",
    "    b2 = tf.Variable(tf.zeros([10]), name='2_biases')\n",
    "    logits = tf.matmul(h1, w2) + b2\n",
    "    return logits\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "x1 = tf.Variable(tf.random_normal([200,100]))\n",
    "x2 = tf.Variable(tf.random_normal([200,100]))\n",
    "logits1 = two_hidden_layers(x1)\n",
    "logits2 = two_hidden_layers(x2)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    writer = tf.summary.FileWriter('./graphs/var_sharing', sess.graph)\n",
    "\n",
    "    sess.run([logits1, logits2])\n",
    "                                    \n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_hidden_layers(x):\n",
    "    w1 = tf.get_variable(\"h1_weights\", [100, 50], initializer=tf.random_normal_initializer())\n",
    "    b1 = tf.get_variable('h1_biases', [50], initializer=tf.constant_initializer(0.0))\n",
    "    h1 = tf.matmul(x, w1) + b1\n",
    "\n",
    "    w2 = tf.get_variable(\"h2_weights\", [50, 10], initializer=tf.random_normal_initializer())\n",
    "    b2 = tf.get_variable('h2_biases', [10], initializer=tf.constant_initializer(0.0))\n",
    "    logits = tf.matmul(h1, w2) + b2\n",
    "    return logits\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "x1 = tf.Variable(tf.random_normal([200,100]))\n",
    "x2 = tf.Variable(tf.random_normal([200,100]))\n",
    "# logits1 = two_hidden_layers(x1)\n",
    "# logits2 = two_hidden_layers(x2) # ValueError: Variable h1_weights already exists, disallowed. Did you mean to set reuse=True in VarScope?\n",
    "\n",
    "with tf.variable_scope(\"two_layers\") as scope:\n",
    "    logits1 = two_hidden_layers(x1)\n",
    "    scope.reuse_variables()\n",
    "    logits2 = two_hidden_layers(x2)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    writer = tf.summary.FileWriter('./graphs/var_sharing', sess.graph)\n",
    "\n",
    "    sess.run([logits1, logits2])\n",
    "                                    \n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fully_connected(x, output_dim, scope):\n",
    "    with tf.variable_scope(scope, reuse=tf.AUTO_REUSE) as scope:\n",
    "        w = tf.get_variable(\"weights\", [x.shape[1], output_dim], initializer=tf.random_normal_initializer())\n",
    "        b = tf.get_variable(\"biases\", [output_dim], initializer=tf.constant_initializer(0.0))\n",
    "        return tf.matmul(x, w) + b\n",
    "\n",
    "def two_hidden_layers(x):\n",
    "    h1 = fully_connected(x, 50, \"h1\")\n",
    "    return fully_connected(h1, 10, \"h2\")\n",
    "    \n",
    "\n",
    "tf.reset_default_graph()\n",
    "x1 = tf.Variable(tf.random_normal([200,100]))\n",
    "x2 = tf.Variable(tf.random_normal([200,100]))\n",
    "with tf.variable_scope(\"two_layers\") as scope:\n",
    "    logits1 = two_hidden_layers(x1)\n",
    "    logits2 = two_hidden_layers(x2)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    writer = tf.summary.FileWriter('./graphs/var_sharing', sess.graph)\n",
    "    sess.run([logits1, logits2])\n",
    "                                    \n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save and Restore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.summary.scalar(\"loss\", self.loss)\n",
    "# tf.summary.histogram(\"histogram loss\", self.loss)\n",
    "# summary_op = tf.summary.merge_all()\n",
    "\n",
    "# saver = tf.train.Saver() # defaults to saving all variables\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "#     sess.run(tf.global_variables_initializer())\n",
    "#     ckpt = tf.train.get_checkpoint_state(os.path.dirname('checkpoints/checkpoint'))\n",
    "#     if ckpt and ckpt.model_checkpoint_path:\n",
    "#         saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "\n",
    "#     writer = tf.summary.FileWriter('./graphs', sess.graph)\n",
    "#     for index in range(10000):\n",
    "#         ...\n",
    "#         loss_batch, _, summary = sess.run([loss, optimizer, summary_op])\n",
    "#         writer.add_summary(summary, global_step=index)\n",
    "\n",
    "#         if (index + 1) % 1000 == 0:\n",
    "#             saver.save(sess, 'checkpoints/skip-gram', index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Control Randomization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.574932\n",
      "-5.9731865\n"
     ]
    }
   ],
   "source": [
    "c = tf.random_uniform([], -10, 10, seed=2)\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(c)) # >> 3.57493\n",
    "    print(sess.run(c)) # >> -5.97319"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.574932\n",
      "3.574932\n"
     ]
    }
   ],
   "source": [
    "c = tf.random_uniform([], -10, 10, seed=2)\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(c)) # >> 3.57493    \n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(c)) # >> 3.57493"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.574932\n",
      "3.574932\n"
     ]
    }
   ],
   "source": [
    "c = tf.random_uniform([], -10, 10, seed=2)\n",
    "d = tf.random_uniform([], -10, 10, seed=2)\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(c)) # >> 3.57493\n",
    "    print(sess.run(d)) # >> 3.57493"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.8672733\n",
      "0.98825264\n"
     ]
    }
   ],
   "source": [
    "tf.set_random_seed(2)\n",
    "c = tf.random_uniform([], -10, 10)\n",
    "d = tf.random_uniform([], -10, 10)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(c)) # >> -4.00752\n",
    "    print(sess.run(d)) # >> -2.98339"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
